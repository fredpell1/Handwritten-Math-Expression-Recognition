{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from model.cnn import CNN\n",
    "from model.encoder import Encoder\n",
    "from model.decoder import Decoder\n",
    "from model.endtoend import HME2LaTeX\n",
    "from model.language import *\n",
    "from data_processing.loadData import HMEDataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXISTING_MODEL_PATH = './trainedmodelsymbols.tar'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model on already seen (training) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = '..\\data\\CROHME2016_data\\data_png\\data_png_trainingSymbols\\iso_GT.txt'\n",
    "images = '..\\\\data\\\\CROHME2016_data\\\\data_png\\\\data_png_trainingSymbols'\n",
    "dataset = HMEDataset(labels, images, problem_type='symbols')\n",
    "BATCH_SIZE = 32\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex = Lang('latex')\n",
    "for labels in dataset.img_labels.iloc[:,1]:\n",
    "    latex.addSentence(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset, BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = torch.nn.utils.rnn.pad_sequence([tensorFromSentence(latex,dataset.img_labels.iloc[i,1]) for i in range(len(dataset.img_labels))], padding_value=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN(device).to(device)\n",
    "encoder = Encoder(512, 256, 32*31, BATCH_SIZE).to(device)\n",
    "decoder = Decoder(1,512,latex.n_words,32*31, BATCH_SIZE,device).to(device)\n",
    "model = HME2LaTeX(cnn,encoder,decoder,words.shape[0],BATCH_SIZE, latex.n_words, 1, 0, words.shape[0],device)\n",
    "checkpoint = torch.load(EXISTING_MODEL_PATH, map_location=torch.device(device))\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = iter(train_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run the cell below to get the accuracy of the model on a sample of size 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img,labels,indices = next(iterator)\n",
    "pred = model(img.float().to(device), None)\n",
    "target = words[:,indices,:].to(device)\n",
    "torch.count_nonzero(pred[:,:,:].topk(1)[1].view(3,32).T[:,0] == target.view(3,32).T[:,1]) / (BATCH_SIZE) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run the cells below to compute the accuracy on all the dataset (will take a lot of time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = torch.zeros(1)\n",
    "i=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader_in_order = DataLoader(dataset, BATCH_SIZE)\n",
    "for i,(img,labels,indices) in enumerate(train_dataloader_in_order):\n",
    "    pred = model(img.float().to(device), None)\n",
    "    target = words[:,indices,:].to(device)\n",
    "    correct += torch.count_nonzero(pred[:,:,:].topk(1)[1].view(3,32).T[:,0] == target.view(3,32).T[:,1])\n",
    "print(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct / (i*BATCH_SIZE), i*BATCH_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model on never seen data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = '..\\data\\CROHME2016_data\\data_png\\data_png_testSymbols\\\\testSymbols_2016_iso_GT.txt'\n",
    "test_images = '..\\data\\CROHME2016_data\\data_png\\data_png_testSymbols\\\\'\n",
    "test_dataset = HMEDataset(test_labels, test_images, problem_type='symbols')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in test_dataset.img_labels.iloc[:,1]:\n",
    "    latex.addSentence(label.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_dataset, BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_words = torch.nn.utils.rnn.pad_sequence([tensorFromSentence(latex,test_dataset.img_labels.iloc[i,1].strip()) for i in range(len(test_dataset.img_labels))], padding_value=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = iter(test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run the cell below to get the accuracy on a sample of the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img,labels,indices = next(iterator)\n",
    "right_indices = [i for i,_ in enumerate(indices) if test_words[1,i,:] != latex.word2index['junk']]\n",
    "pred = model(img.float().to(device), None)\n",
    "target = test_words[:,indices,:].to(device)\n",
    "torch.count_nonzero(pred[:,right_indices,:].topk(1)[1].view(3,len(right_indices)).T[:,0] == target[:,right_indices,:].view(3,len(right_indices)).T[:,1]) / (len(right_indices)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_dataset, BATCH_SIZE, shuffle=True)\n",
    "correct = torch.zeros(1)\n",
    "i = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run the cell below to get the testing accuracy on all the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,(img,labels,indices) in enumerate(test_dataloader):\n",
    "    right_indices = [j for j,_ in enumerate(indices) if test_words[1,j,:] != latex.word2index['junk']]\n",
    "    pred = model(img.float().to(device), None)\n",
    "    target = test_words[:,indices,:].to(device)\n",
    "    correct += torch.count_nonzero(pred[:,right_indices,:].topk(1)[1].view(3,len(right_indices)).T[:,0] == target[:,right_indices,:].view(3,len(right_indices)).T[:,1])\n",
    "    print(correct)\n",
    "correct / (i * BATCH_SIZE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6b50a1d762d4853fe27a86530a9bcdf85f59f22d585aca88e4f703f55ce46be5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
