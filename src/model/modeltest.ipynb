{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to showcase how to use the model\n",
    "\n",
    "## CLEAR OUTPUT OF THE NOTEBOOK BEFORE COMMITING/PUSHING\n",
    "\n",
    "The path may not work for you as they are hardcoded for a sample of the data on my machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.io import read_image\n",
    "import torchvision.transforms as T\n",
    "from cnn import CNN\n",
    "from encoder import Encoder\n",
    "from decoder import Decoder\n",
    "import os\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_PATH = '../../data/CROHME2016_data/data_png/subset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_files(file):\n",
    "    \"\"\"Utility function to sort the file names according to their number\"\"\"\n",
    "    match = re.match(r'\\D*(?P<num>\\d+)\\..*', file)\n",
    "    if match:\n",
    "        return int(match.group('num'))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the images in one tensor\n",
    "batch = torch.zeros((11,1,304,304)).to(device)\n",
    "tree = next(os.walk(FOLDER_PATH))\n",
    "files = [file for file in tree[-1] if file.endswith('png')]\n",
    "files.sort(key=sort_files)\n",
    "for i,file in enumerate(files):\n",
    "    pic = read_image(f\"{FOLDER_PATH}/{file}\").float().to(device)\n",
    "    batch[i] += pic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the labels in a dictionary\n",
    "labels = dict()\n",
    "with open(f\"{FOLDER_PATH}iso_GT.txt\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        labels[row[0]] = row[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Below code is from https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n",
    "\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    seq = [SOS_token]\n",
    "    seq.extend(indexes)\n",
    "    return torch.tensor(seq, dtype=torch.long).view(-1, 1).to(device)\n",
    "\n",
    "\n",
    "\n",
    "REPLACEMENTS = [\n",
    "    ('(', '( '),\n",
    "    ('{', '{ '),\n",
    "    ('[', '[ '),\n",
    "    (')', ' )'),\n",
    "    ('}', ' }'),\n",
    "    (']', ' ]'),\n",
    "    ('=', ' = '),\n",
    "    ('+', ' + '),\n",
    "    ('-', ' - '),\n",
    "    ('^', ' ^ '),\n",
    "    ('*', ' * '),\n",
    "    ('$', ' $ '),\n",
    "    (',', ' , ')\n",
    "]\n",
    "\n",
    "def normalize(string, replacements):\n",
    "    for replacement in replacements:\n",
    "        string = string.replace(replacement[0], replacement[1])\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [8],\n",
       "        [1]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create our embedding of the data\n",
    "latex = Lang('latex')\n",
    "for label in labels.values():\n",
    "    latex.addWord(label)\n",
    "tensorFromSentence(latex, '\\\\sum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the end-to-end system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = CNN(device).to(device)\n",
    "encoder = Encoder(512, 256, 32*31, 11).to(device)\n",
    "decoder = Decoder(1,512, latex.n_words, 32*31, 11, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = torch.zeros((3,11,1)).to(device)\n",
    "for i,label in enumerate(labels.values()):\n",
    "    sentence = tensorFromSentence(latex, label)\n",
    "    words[:,i,:] += sentence\n",
    "words.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from endtoend import HME2LaTeX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HME2LaTeX(net, encoder, decoder, 3, 11, 10, 1, 0, 3, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "loss = torch.nn.CrossEntropyLoss() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('model.tar')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "l = checkpoint['loss']\n",
    "model.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(30):\n",
    "    optimizer.zero_grad()\n",
    "    probs = model(batch,words)\n",
    "    l = torch.zeros(1).to(device)\n",
    "    for i in range(2):\n",
    "        l += loss(probs[:2][i].type(torch.float32).to(device), words[1:][i].reshape((11)).type(torch.long).to(device))\n",
    "    l.backward()\n",
    "    optimizer.step()\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'model_state_dict' : model.state_dict(),\n",
    "    'optimizer_state_dict' : optimizer.state_dict(),\n",
    "    'loss': l\n",
    "}, './model.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(batch,words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 1],\n",
       "        [6, 1],\n",
       "        [2, 1],\n",
       "        [5, 1],\n",
       "        [6, 1],\n",
       "        [7, 1],\n",
       "        [6, 1],\n",
       "        [2, 1],\n",
       "        [9, 1],\n",
       "        [6, 1],\n",
       "        [5, 1]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[:2].topk(1)[1].view(2,11).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(86.3636)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy\n",
    "torch.count_nonzero(words[1:].view(2,11).T == pred[:2].topk(1)[1].view(2,11).T.cpu()) / 22 * 100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6b50a1d762d4853fe27a86530a9bcdf85f59f22d585aca88e4f703f55ce46be5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
